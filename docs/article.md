# Детектирование SSH-туннелей
Наверное, нельзя найти разработчика, который хоть раз не пользовался протоколом SSH. Мощный инструмент, который используется для удалённой работы или передачи данных. Все данные передаются в зашифрованном виде, широко распространён.

И, наверное, многие знают об основах безопасности — не передавать пароли, запрещать доступ от рута, правила подключения и прочее.П родолжая тему безопасности, нельзя обойти вниманием SSH-туннели и методы их обнаружения. Многие начинающие, даже продвинутые разработчики не знакомы с ними. SSH-туннели — это безопасные соединения между локальной машиной и удалённым сервером через функцию перенаправления портов. Они создаются с целью обеспечить безопасную передачу через ненадёжные сети.

Однако эту же функциональность могут использовать злоумышленники для обхода правил межсетевых экранов и скрытия своей активности. Именно для защиты от таких махинаций надо уметь детектировать такие соединения.

Эта статья посвящена обзору и детектированию SSH-туннелей.

---

Давайте разберём работу SSH-туннелей в принципе. Как сказано выше, их используют многие системные администраторы, т. к. туннели помогают получать доступ к ресурсу, базе данных или сервису, который находится в закрытой сети, когда есть SSH-доступ к одному из серверов в этой сети.

Чтобы вручную не слать запросы на промежуточном сервере, в основном пользуются процессом переадресацией портов (Port Forwarding):

1. Допустим наличие сервера S1, к которому у нас есть полный доступ на любой из существующих портов.
2. Есть другой сервер S2, к 80 порту которого мы хотим получить доступ через S1.
3. И через Port Forwarding мы делаем так, чтобы через открытый порт 80 на S1 мы слали запросы на этот же порт в S2 и получали ответ. А также мы можем открыть другой порт (условно 70), который будет переадресовывать запрос на 80 порт другого сервера S3.

То есть, процесс использования туннелей — это использование SSH как прокси. Туннели могут быть локальными, удалёнными и динамическими. Стоит, наверное, прояснить, что динамическое туннелирование — это метод, при котором SSH-клиент настраивается как SOCKS-прокси. Соответственно, Port Forwarding тоже динамический. И само туннелирование в принципе работает по одному SSH-каналу.

Давайте перейдём непосредственно к самому туннелированию. В простейшей форме SSH-туннель открывает порт на локальном хосте, который подключается к другому порту другого хоста (на другом конце туннеля):

```bash
$ ssh -L 81:127.0.0.1:80 user@remoteserver
```

Флаг `-L` как раз и отвечает за туннелирование. Его параметр можно представить как локальный хост прослушивания: в этом примере порт 81 прослушивается на нашей локальной системе. А после идёт переадресация через 80 порт на удалённый сервер (remoteserver), причём к локалхосту на удалённом сервере.

Разберём другой пример:

```bash
$ ssh -L 127.0.0.1:81:example.com:80
```

Эта команда уже перенаправляет локальные подключения от 127.0.0.1:81 на 80 порт example.com. Трафик между локальной системой и SSH-сервером идёт по этому туннелю, а трафик между SSH-сервером и example.com — нет.

Если подниматься выше, то можно сделать так, чтобы порты прослушивания связывались с другими узлами локальной сети:

```bash
$ ssh -L 0.0.0.0:81:127.0.0.1:80 user@remoteserver
```

Здесь уже туннель перенаправляет запросы от remoteserver к локалхосту на порту 80. Трафик с remoteserver к 127.0.0.1 уже не в SSH-туннели — его сервер будет считать remoteserver источником запросов.

Выше были примеры работы локальных туннелей, так что переходим к удалённому. Это способ проброса сетевого трафика с удалённого сервера на локальную машину через SSH-соединение:

```bash
$ ssh -R 0.0.0.0:81:localhost:80 user@target
```

В примере выше мы поднимаем на хосте удалённого сервера порт 81, направленный трафик на который будет идти через туннель на порт 80 хоста target. То есть 0.0.0.0 это уже не локальный, а удалённый сервер. Трафик удалённого сервера пробрасывается до локальной машины. Так можно закрепиться в инфраструктуре.

Кроме этого, можно сделать *обратный* ssh-туннель:

```bash
$ ssh -v -R 0.0.0.0:81:127.0.0.1:80 192.168.1.100 user@remoteserver
```

То есть здесь мы настраиваем прослушивающий порт уже на удалённой машине, которая уже будет подключаться к нам на локалхост к нашему порту. В примере устанавливается соединение с порта 81 на remoteserver к порту 80 через наш клиент.

Ну и динамический туннель идёт через флаг `-D`:

```bash
$ ssh -D 3000 REMOTESERVER
```

Гибкий вариант, который позволяет открыть на своём локальном хосте SOCKS-прокси-сервер и использовать промежуточный сервер для подключения ко всему серверу. Такие туннели оставляют также минимум артефактов и следов, что делают их самыми скрытыми.

---

Согласитесь, удобно и довольно просто в использовании. Но такой функциональностью может воспользоваться не только сисадмин в вашей компании, а злоумышленник (а особенно динамический туннель, который позволит получить доступ не к одному серверу, а ко всей вашей инфраструктуре). Он, используя функционал SSH-туннелей может обойти сетевые фильтры, ограничения, фаерволлы и весь защищаемый периметр. А также помогает сокрыть и анонимизировать трафик, организацию обратного доступа (через тот же reverse tunnel, который описан выше) и проброс вредоносных инструментов как сама цель атаки.

Это создаёт трудности для детектирования зловредных манипуляций, и поэтому тем, кто занимается защитой сервера, и, в частности, детектирования этих самых туннелей, важно понимать с какой целью используется туннель. Также можно усложнить или даже исключить возможность поднятия туннеля, а в случае если туннель поднят — обнаружить его на уровне ОС и изолировать самого инициатора данного процесса.

## Детектирование
Итак, переходим к цели нашей статьи — анализ bind/connect от sshd и детектирование ssh-туннелей. Как вы знаете, на каждом linux-сервере вместе с ssh работает его демон — SSHD, и он уже обслуживает все соединения. Этот демон генерирует два основных системных вызова — это bind для открытия порта, и connect для подключения к хосту.

Именно эти вызовы чаще всего сигнализируют о создании SSH-туннеля. Так что можно логгировать их через системные средства (auditd) и отсутствует необходимость анализа сетевого трафика.

> Auditd (Linux Audit Daemon) — компонент пользовательского пространства подсистемы аудита Linux. Это системный демон, который перехватывает системные вызовы от приложений и пользователей, оценивает их по набору предопределённых правил и записывает срабатывания правил в централизованный журнал аудита системных событий.

Давайте поподробнее разберём каждый вызов в контексте ssh-туннелей. Мы используем именно auditd для детектирования, а не стандартные логи SSH по причине, что туннели мы можем обнаружить именно что на уровне системы.

### Syscall Bind
Этот вызов создаёт серверный сокет, к которому могут подключаться удалённые клиенты. В случае удалённого туннеля на целевом сервере будет сделан `bind()`, прослушивающий определённый порт и пересылающий данные на хост-источник туннеля.

Допустим, где-то был создан удалённый ssh-туннель:

```bash
$ ssh -R 0.0.0.0:9999:localhost:8080 root@11.62.10.146
```

И мы можем получить примерно такой сырой лог вызова:

![](https://habrastorage.org/webt/ns/v0/5y/nsv05yuefjezbh-itsfse-qfm00.png)

В первую очередь нам важен какой открылся порт и на каком интерфейсе (если в поле интерфейса 4 нуля, значит он открыт для всех). После, что за сессия и какого пользователя. По номеру сессии можно найти как пользователь был авторизован

### Syscall Connect
Для вызова `connect()` ситуация похожа. Только в первую очередь нас интересует, к какому хосту прокидывается доступ и куда идёт подключение.

Например, при команде создания локального туннеля:

```bash
$ ssh -L 9999:11.62.10.249:8080 root@11.62.10.146
```

Мы можем получить такой лог вызова:

![](https://habrastorage.org/webt/a5/dh/rt/a5dhrth_gbuuw1hekujyowwdtwo.png)

Здесь также есть и сессия, и пользователь.

## Настройка мониторинга
Мы разобрались с тем, какие события нам нужно логгировать и что нам нужно. Теперь нам нужно настроить сбор таких событий и их мониторинг через `auditd`.

Отредактируйте файл `/etc/audit/rules.d`

![](https://habrastorage.org/webt/ei/eh/ot/eiehotse0xcrekov1gjx6c-fema.png)

Данная конфигурация собирает с linux-хостов вызовы `bind` и `connect`, о которых мы говорили ранее.

Что ещё важно — мы не просто мониторим все вызовы, так как в рамках локального хоста происходит много соединений и прослушиваний. Здесь нам помогает параметр `a2` — длина структуры sockaddr (addrlen). С его помощью мы можем ограничить события только теми, которые действительно относятся к сетевым соединениям по протоколам IPv4/IPv6.

Что в итоге? Данная конфигурация auditd помогает логгировать все системные вызовы connect и bind только если это касается сетевых подключений по IPv4/IPv6:

+ a2=0x10 — фильтруются вызовы connect/bind для IPv4.
+ a2=0x1C — то же самое, но для IPv6.

Настроив сбор таких событий, перейдём к созданию детектирующей логики. Разберём на примере Sigma Rule и KUMA Rule.

Sigma Rule — это формат описания правил для обнаружения угроз в логах, разработанный проектом SigmaHQ. Это стандартизированный стандарт с открытым исходным кодом, который позволяет создавать и обмениваться правилами обнаружения в разных системах анализа логов (SIEM).

Правила Sigma Rule в нашем случае:

![](https://habrastorage.org/webt/sy/gq/ab/sygqab7lhph4uprfm2nyk3pn3sq.png)

KUMA Rule — это правила корреляции в системе Kaspersky Unified Monitoring and Analysis Platform (KUMA) — решении класса SIEM для мониторинга и анализа инцидентов информационной безопасности (ИБ).

И правила Kuma Rule соответственно:

![](https://habrastorage.org/webt/61/eg/rs/61egrst6u8ljhczlmtlpryzxlx0.png)

Сама логика относительно простая — мы ищем системные вызовы connect или bind от исполняемого файла sshd. Но кроме этого, самое важное чтобы command line (proctitle) содержал в себе строку «sshd». Без этого мы иначе будем реагировать на обычные подключения по SSH. А вот процессы туннелей уже содержат эту строку.

## Профилирование
Но перед тем, как запускать наше созданное правило, необходимо заняться профилированием. Для логики выше обычно требуется 300 сработок в неделю на 100 хостов auditd. Это слишком много, лучше снизить количество сработок.

Если какое-то правило плодит огромное количество ложных срабатываний, то не стоит его внедрять, даже если оно очень интересное. К примеру, если в компании часто используют ssh-туннелирование, то при обильном количестве ложных срабатываний дежурные могут не обратить внимание на реальное вредоносное подключение.

Чтобы избавиться от такого и снизить количество уведомлений:

1. Исключаем подстроку `Proctitle contains [listener] 0 of 10-100 startups` — это логовая запись демона SSH об активных подключениях.
2. Исключаем целевой порт 0 (неопределённый порт, тестирование или отладка, ошибки).
3. Если используется x-сервер, то исключаем точные целевые порты связанные с ним. Если невозможно исключить конкретные порты — то исключать диапазон (например, чтобы целевой порт не был в диапазоне от 6000 до 6200).

## Пример расследования Connect
Допустим, была проведена настройка мониторинга и профилирование, что же делать, если мы зафиксировали сработанный случай?

Давайте разберём на примере, вот исходные данные:

![](https://habrastorage.org/webt/zg/cu/7v/zgcu7vz9chl4k_3rbxn28f1tihk.png)

Событие мы зафиксировали на девайс-адресе 11.62.10.146. Произошло там следующее:

![](https://habrastorage.org/webt/fh/6k/s1/fh6ks1q80s5dyfrfbw4xvelpa3g.png)

Процесс SSHD выполнил подключение на HTTP-порт 8080 целевого хоста 11.62.10.249. Сразу задаём вопрос — зачем sshd обращается на HTTP порт?

Нам стоит обратить внимание на номер сессии (в данном случае — 33440). Мы видим как был выполнен вход на хост в рамках этой сессии, и мы выходим на хост-источник — это хост 11.62.10.253.

Далее у нас два варианта:
1. `connect`. Мы идём на этот хост и смотрим с него события, если он на мониторинге:

Злоумышленник создал локальный туннель на своём хосте «Hacker» и в рамках этого туннеля у него была цель получить прямой доступ с хоста Hacker на хост Target, на критический сервер на порту 8080. Он создал локальный туннель, обратившись на порт 9999 своего хоста Hacker, и сквозь туннель через ProxyServer получил доступ к хосту Target.

![](https://habrastorage.org/webt/lo/af/7q/loaf7q8d8q61fjb03wo2iwbjt2o.png)

Аналогичным образом connect будет провоцировать динамический туннель. И в данном случае нам помогает исключительно наше правило — мы не будем знать какое ПО и команды он использовал. Но можем отловить момент подключения благодаря отработке.

2. `bind`. Расследование начинается аналогичным образом:

![](https://habrastorage.org/webt/zj/nm/cf/zjnmcfsz6lei2elzp_sulqtghf8.png)

Смотрим на ID сессии, и понимаем что уже порт открыт на прослушивание, но алгоритм тот же самый: мы выясняем каким образом было подключение к хосту, на котором зафиксировали это событие.

И в таком случае мы можем также построить гипотезу, либо посмотреть по хостам событий с хоста источника, что делал злоумышленник.

В данном случае, подключение было с хоста Target. Если локальный туннель поднимался с хоста атакующего, то удалённый туннель буквально публикует для него. С хоста Target прописали в задачнике Linux cron. Там была заключена команда, которая на регулярной основе поднимала удалённый туннель. И теперь злоумышленник в любой момент с любого хоста, с которого есть доступ к ProxyServer, обратившись на порт 9999, сквозь удалённый туннель получали доступ к интересующему его сервису на порту 8080 хоста Target.

![](https://habrastorage.org/webt/mc/ox/hc/mcoxhcko0pf3eqshubkjsrzhcjw.png)

В случае удалённого туннеля мы «публикуем» локальный порт хоста 11.62.10.253:8080 через хост 11.62.10.146:9999.

Цель злоумышленника может заключаться скорее всего: либо в публикации сервиса 11.62.10.253:8080, доступного только с 11.62.10.146, либо чтобы закрепить через команду в cron.

## Hardening
Перейдём к процессу повышения безопасности сервера, в частности — ssh.

Если следовать максимальной безопасности, то можно выставить в `/etc/ssh/sshd_config` следующие параметры:

+ `AllowTcpForwarding no`
+ `GatewayPorts no`
+ `PermitTunnel no`
+ `PermitRootLogin no`
+ `PermitRootLogin without-password no`

> Не бегите прямо сейчас копировать их! Сначала изучите требования ваших сервисов и выставляйте нужные параметры в зависимости от вашей конфигурации. В данном случае настройка ssh запрещает маршрутизацию и туннелирование сетевого трафика.

# Заключение
В конце такой длинной темы можно сказать, что всегда стоит иметь задокументированные стандарты безопасности (например, для харденинга ssh, как в случае выше). SSH-туннели — иногда полезная вещь, но стоит понимать, что она удобна не только для вас, но и для злоумышленников. В этой статье было рассмотрено детектирование SSH-туннелей на основе системных вызовов от процесса демона SSH — он покрывает большинство случаев. Это уникальная вещь, с которой много кто может встретиться.

Кроме мониторинга системных вызовов, можно пойти другими путями: анализом сетевого трафика на аномалии, метрика потребления ресурсов sshd, в зависимости от ваших требований. В основном же логирование bind и connect позволяет более целостно посмотреть на картину.

Если у вас остались вопросы, замечания или иные полезные заметки — пишите в комментарии. Спасибо за прочтение статьи!

## Источники

- [Практические советы, примеры и туннели SSH](https://habr.com/ru/articles/435546/#2)
